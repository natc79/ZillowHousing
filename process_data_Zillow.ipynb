{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zillow Housing Data (Initial File Processing)\n",
    "\n",
    "This code reads in files connected with the Kaggle 2017 Zillow Housing Competition stage 1 where the goal was to find a model that could best predict the z-estimate log error which is essentially the residual error term from Zillow's housing price model.  \n",
    "\n",
    "The main purpose of this code is to undertake an initial exploration of the data, process the data in chunks, throw out columns that contain insufficient amounts of observations, convert the data into integers or factors where possible and ultimately to output a file CSV file. The file compression takes the dataset from approximately 1.7GBs to around 15MBs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>airconditioningtypeid</th>\n",
       "      <th>architecturalstyletypeid</th>\n",
       "      <th>basementsqft</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>buildingclasstypeid</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>calculatedbathnbr</th>\n",
       "      <th>decktypeid</th>\n",
       "      <th>finishedfloor1squarefeet</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>finishedsquarefeet12</th>\n",
       "      <th>finishedsquarefeet13</th>\n",
       "      <th>finishedsquarefeet15</th>\n",
       "      <th>finishedsquarefeet50</th>\n",
       "      <th>finishedsquarefeet6</th>\n",
       "      <th>fips</th>\n",
       "      <th>fireplacecnt</th>\n",
       "      <th>fullbathcnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73026.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73026.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5068.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5068.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1776.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1776.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  airconditioningtypeid  architecturalstyletypeid  basementsqft  \\\n",
       "0  10754147                    NaN                       NaN           NaN   \n",
       "1  10759547                    NaN                       NaN           NaN   \n",
       "2  10843547                    NaN                       NaN           NaN   \n",
       "3  10859147                    NaN                       NaN           NaN   \n",
       "4  10879947                    NaN                       NaN           NaN   \n",
       "\n",
       "   bathroomcnt  bedroomcnt  buildingclasstypeid  buildingqualitytypeid  \\\n",
       "0          0.0         0.0                  NaN                    NaN   \n",
       "1          0.0         0.0                  NaN                    NaN   \n",
       "2          0.0         0.0                  NaN                    NaN   \n",
       "3          0.0         0.0                  3.0                    7.0   \n",
       "4          0.0         0.0                  4.0                    NaN   \n",
       "\n",
       "   calculatedbathnbr  decktypeid  finishedfloor1squarefeet  \\\n",
       "0                NaN         NaN                       NaN   \n",
       "1                NaN         NaN                       NaN   \n",
       "2                NaN         NaN                       NaN   \n",
       "3                NaN         NaN                       NaN   \n",
       "4                NaN         NaN                       NaN   \n",
       "\n",
       "   calculatedfinishedsquarefeet  finishedsquarefeet12  finishedsquarefeet13  \\\n",
       "0                           NaN                   NaN                   NaN   \n",
       "1                           NaN                   NaN                   NaN   \n",
       "2                       73026.0                   NaN                   NaN   \n",
       "3                        5068.0                   NaN                   NaN   \n",
       "4                        1776.0                   NaN                   NaN   \n",
       "\n",
       "   finishedsquarefeet15  finishedsquarefeet50  finishedsquarefeet6  fips  \\\n",
       "0                   NaN                   NaN                  NaN  6037   \n",
       "1                   NaN                   NaN                  NaN  6037   \n",
       "2               73026.0                   NaN                  NaN  6037   \n",
       "3                5068.0                   NaN                  NaN  6037   \n",
       "4                1776.0                   NaN                  NaN  6037   \n",
       "\n",
       "   fireplacecnt  fullbathcnt  \n",
       "0           NaN          NaN  \n",
       "1           NaN          NaN  \n",
       "2           NaN          NaN  \n",
       "3           NaN          NaN  \n",
       "4           NaN          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "#might need to process in chunks because too big\n",
    "temp = pd.read_csv(\"properties_2016.csv\", encoding = \"ISO-8859-1\", nrows=20)\n",
    "temp.iloc[:,0:20].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6037.0    2009362\n",
       "6059.0     741565\n",
       "6111.0     222853\n",
       "Name: fips, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv(\"properties_2016.csv\", encoding = \"ISO-8859-1\", usecols=['fips'])\n",
    "temp['fips'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90811, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transactiondate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11016594</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14366692</td>\n",
       "      <td>-0.1684</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12098116</td>\n",
       "      <td>-0.0040</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12643413</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>2016-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14432541</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>2016-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  logerror transactiondate\n",
       "0  11016594    0.0276      2016-01-01\n",
       "1  14366692   -0.1684      2016-01-01\n",
       "2  12098116   -0.0040      2016-01-01\n",
       "3  12643413    0.0218      2016-01-02\n",
       "4  14432541   -0.0050      2016-01-02"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_2016.csv\", encoding = \"ISO-8859-1\",parse_dates=[\"transactiondate\"])\n",
    "print(train.shape)\n",
    "temp_train = pd.read_csv(\"train_2016.csv\", encoding = \"ISO-8859-1\", nrows=20)\n",
    "temp_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data\n",
      "parcelid                              0\n",
      "airconditioningtypeid           2173698\n",
      "architecturalstyletypeid        2979156\n",
      "basementsqft                    2983589\n",
      "bathroomcnt                       11462\n",
      "bedroomcnt                        11450\n",
      "buildingclasstypeid             2972588\n",
      "buildingqualitytypeid           1046729\n",
      "calculatedbathnbr                128912\n",
      "decktypeid                      2968121\n",
      "finishedfloor1squarefeet        2782500\n",
      "calculatedfinishedsquarefeet      55565\n",
      "finishedsquarefeet12             276033\n",
      "finishedsquarefeet13            2977545\n",
      "finishedsquarefeet15            2794419\n",
      "finishedsquarefeet50            2782500\n",
      "finishedsquarefeet6             2963216\n",
      "fips                              11437\n",
      "fireplacecnt                    2672580\n",
      "fullbathcnt                      128912\n",
      "garagecarcnt                    2101950\n",
      "garagetotalsqft                 2101950\n",
      "hashottuborspa                  2916203\n",
      "heatingorsystemtypeid           1178816\n",
      "latitude                          11437\n",
      "longitude                         11437\n",
      "lotsizesquarefeet                276099\n",
      "poolcnt                         2467683\n",
      "poolsizesum                     2957257\n",
      "pooltypeid10                    2948278\n",
      "pooltypeid2                     2953142\n",
      "pooltypeid7                     2499758\n",
      "propertycountylandusecode         12277\n",
      "propertylandusetypeid             11437\n",
      "propertyzoningdesc              1006588\n",
      "rawcensustractandblock            11437\n",
      "regionidcity                      62845\n",
      "regionidcounty                    11437\n",
      "regionidneighborhood            1828815\n",
      "regionidzip                       13980\n",
      "roomcnt                           11475\n",
      "storytypeid                     2983593\n",
      "threequarterbathnbr             2673586\n",
      "typeconstructiontypeid          2978470\n",
      "unitcnt                         1007727\n",
      "yardbuildingsqft17              2904862\n",
      "yardbuildingsqft26              2982570\n",
      "yearbuilt                         59928\n",
      "numberofstories                 2303148\n",
      "fireplaceflag                   2980054\n",
      "structuretaxvaluedollarcnt        54982\n",
      "taxvaluedollarcnt                 42550\n",
      "assessmentyear                    11439\n",
      "landtaxvaluedollarcnt             67733\n",
      "taxamount                         31250\n",
      "taxdelinquencyflag              2928755\n",
      "taxdelinquencyyear              2928753\n",
      "censustractandblock               75126\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Examine missing values for all the variables in the list\n",
    "#get understanding of some of the count values, is it safe to replace them with a 0?\n",
    "\n",
    "chunk_iter = pd.read_csv(\"properties_2016.csv\", encoding = \"ISO-8859-1\", chunksize=3000)\n",
    "\n",
    "cnt = 0\n",
    "for chunk in chunk_iter:\n",
    "    if cnt == 0:\n",
    "        misscounts = chunk.isnull().sum()\n",
    "        garagecarcntvals = chunk[\"garagecarcnt\"].value_counts()\n",
    "        poolcntvals = chunk[\"poolcnt\"].value_counts()\n",
    "        fireplacecntvals = chunk[\"fireplacecnt\"].value_counts()\n",
    "    else:\n",
    "        misscounts += chunk.isnull().sum()\n",
    "        garagecarcntvals += chunk[\"garagecarcnt\"].value_counts()\n",
    "        poolcntvals += chunk[\"poolcnt\"].value_counts()\n",
    "        fireplacecntvals += chunk[\"fireplacecnt\"].value_counts()\n",
    "    cnt += 1\n",
    "\n",
    "print(\"Missing Data\")\n",
    "print(misscounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing observations\n",
    "\n",
    "The number of missing observations contained within the train dataset accounts for a significant proportion of the total observations in the dataset.  Things such as architerctural style, basement square footage are missing for the large majority of houses in the database.  The safest bet would be to throw out all of the data where the majority of properties having missing data and focus only on keeping variables where less than 50% of observations are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>airconditioningtypeid</th>\n",
       "      <th>architecturalstyletypeid</th>\n",
       "      <th>basementsqft</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>buildingclasstypeid</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>calculatedbathnbr</th>\n",
       "      <th>decktypeid</th>\n",
       "      <th>...</th>\n",
       "      <th>yardbuildingsqft26</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>numberofstories</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>landtaxvaluedollarcnt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "      <th>censustractandblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>273310.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>999992.000000</td>\n",
       "      <td>999997.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>651930.000000</td>\n",
       "      <td>960325.000000</td>\n",
       "      <td>5739.0</td>\n",
       "      <td>...</td>\n",
       "      <td>915.000000</td>\n",
       "      <td>983698.000000</td>\n",
       "      <td>229418.000000</td>\n",
       "      <td>9.852500e+05</td>\n",
       "      <td>9.893440e+05</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>9.808670e+05</td>\n",
       "      <td>9.933410e+05</td>\n",
       "      <td>18863.000000</td>\n",
       "      <td>9.783470e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.296211e+07</td>\n",
       "      <td>1.927826</td>\n",
       "      <td>7.185823</td>\n",
       "      <td>644.014925</td>\n",
       "      <td>2.209717</td>\n",
       "      <td>3.087610</td>\n",
       "      <td>3.730841</td>\n",
       "      <td>5.784104</td>\n",
       "      <td>2.300198</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>277.095082</td>\n",
       "      <td>1964.279903</td>\n",
       "      <td>1.401045</td>\n",
       "      <td>1.717099e+05</td>\n",
       "      <td>4.215594e+05</td>\n",
       "      <td>2014.999532</td>\n",
       "      <td>2.527255e+05</td>\n",
       "      <td>5.385854e+03</td>\n",
       "      <td>13.867359</td>\n",
       "      <td>6.048501e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.619029e+06</td>\n",
       "      <td>3.143820</td>\n",
       "      <td>2.356177</td>\n",
       "      <td>507.503315</td>\n",
       "      <td>1.079544</td>\n",
       "      <td>1.275763</td>\n",
       "      <td>0.496289</td>\n",
       "      <td>1.805565</td>\n",
       "      <td>1.002337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>369.448200</td>\n",
       "      <td>23.441561</td>\n",
       "      <td>0.543300</td>\n",
       "      <td>4.612234e+05</td>\n",
       "      <td>7.801097e+05</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>4.502451e+05</td>\n",
       "      <td>9.304081e+03</td>\n",
       "      <td>2.238037</td>\n",
       "      <td>4.724418e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.071172e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1808.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.540000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.037101e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.163642e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>264.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.474925e+04</td>\n",
       "      <td>1.795390e+05</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>7.461900e+04</td>\n",
       "      <td>2.459830e+03</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.037320e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.253713e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>1963.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.226025e+05</td>\n",
       "      <td>3.060090e+05</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.670000e+05</td>\n",
       "      <td>3.991940e+03</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.037572e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.409094e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>822.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>311.000000</td>\n",
       "      <td>1981.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.969398e+05</td>\n",
       "      <td>4.885282e+05</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>3.071720e+05</td>\n",
       "      <td>6.203260e+03</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>6.059042e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.632759e+08</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4144.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.514860e+08</td>\n",
       "      <td>2.827860e+08</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>9.024622e+07</td>\n",
       "      <td>3.458861e+06</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>4.830301e+14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           parcelid  airconditioningtypeid  architecturalstyletypeid  \\\n",
       "count  1.000000e+06          273310.000000               1975.000000   \n",
       "mean   1.296211e+07               1.927826                  7.185823   \n",
       "std    2.619029e+06               3.143820                  2.356177   \n",
       "min    1.071172e+07               1.000000                  2.000000   \n",
       "25%    1.163642e+07               1.000000                  7.000000   \n",
       "50%    1.253713e+07               1.000000                  7.000000   \n",
       "75%    1.409094e+07               1.000000                  7.000000   \n",
       "max    1.632759e+08              13.000000                 21.000000   \n",
       "\n",
       "       basementsqft    bathroomcnt     bedroomcnt  buildingclasstypeid  \\\n",
       "count    536.000000  999992.000000  999997.000000          4280.000000   \n",
       "mean     644.014925       2.209717       3.087610             3.730841   \n",
       "std      507.503315       1.079544       1.275763             0.496289   \n",
       "min       25.000000       0.000000       0.000000             1.000000   \n",
       "25%      264.750000       2.000000       2.000000             3.000000   \n",
       "50%      529.000000       2.000000       3.000000             4.000000   \n",
       "75%      822.250000       3.000000       4.000000             4.000000   \n",
       "max     3419.000000      20.000000      20.000000             5.000000   \n",
       "\n",
       "       buildingqualitytypeid  calculatedbathnbr  decktypeid  \\\n",
       "count          651930.000000      960325.000000      5739.0   \n",
       "mean                5.784104           2.300198        66.0   \n",
       "std                 1.805565           1.002337         0.0   \n",
       "min                 1.000000           1.000000        66.0   \n",
       "25%                 4.000000           2.000000        66.0   \n",
       "50%                 7.000000           2.000000        66.0   \n",
       "75%                 7.000000           3.000000        66.0   \n",
       "max                12.000000          20.000000        66.0   \n",
       "\n",
       "              ...           yardbuildingsqft26      yearbuilt  \\\n",
       "count         ...                   915.000000  983698.000000   \n",
       "mean          ...                   277.095082    1964.279903   \n",
       "std           ...                   369.448200      23.441561   \n",
       "min           ...                    12.000000    1808.000000   \n",
       "25%           ...                   100.000000    1950.000000   \n",
       "50%           ...                   168.000000    1963.000000   \n",
       "75%           ...                   311.000000    1981.000000   \n",
       "max           ...                  4144.000000    2015.000000   \n",
       "\n",
       "       numberofstories  structuretaxvaluedollarcnt  taxvaluedollarcnt  \\\n",
       "count    229418.000000                9.852500e+05       9.893440e+05   \n",
       "mean          1.401045                1.717099e+05       4.215594e+05   \n",
       "std           0.543300                4.612234e+05       7.801097e+05   \n",
       "min           1.000000                1.000000e+00       1.000000e+00   \n",
       "25%           1.000000                7.474925e+04       1.795390e+05   \n",
       "50%           1.000000                1.226025e+05       3.060090e+05   \n",
       "75%           2.000000                1.969398e+05       4.885282e+05   \n",
       "max          41.000000                2.514860e+08       2.827860e+08   \n",
       "\n",
       "       assessmentyear  landtaxvaluedollarcnt     taxamount  \\\n",
       "count  1000000.000000           9.808670e+05  9.933410e+05   \n",
       "mean      2014.999532           2.527255e+05  5.385854e+03   \n",
       "std          0.034464           4.502451e+05  9.304081e+03   \n",
       "min       2001.000000           1.000000e+00  2.540000e+00   \n",
       "25%       2015.000000           7.461900e+04  2.459830e+03   \n",
       "50%       2015.000000           1.670000e+05  3.991940e+03   \n",
       "75%       2015.000000           3.071720e+05  6.203260e+03   \n",
       "max       2015.000000           9.024622e+07  3.458861e+06   \n",
       "\n",
       "       taxdelinquencyyear  censustractandblock  \n",
       "count        18863.000000         9.783470e+05  \n",
       "mean            13.867359         6.048501e+13  \n",
       "std              2.238037         4.724418e+11  \n",
       "min              2.000000         6.037101e+13  \n",
       "25%             14.000000         6.037320e+13  \n",
       "50%             14.000000         6.037572e+13  \n",
       "75%             15.000000         6.059042e+13  \n",
       "max             98.000000         4.830301e+14  \n",
       "\n",
       "[8 rows x 53 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv(\"properties_2016.csv\", encoding = \"ISO-8859-1\", nrows=1000000, low_memory=False)\n",
    "temp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this function clean some of the data particular to Zillow\n",
    "def clean_zillow_chunk(chunk,delete=0): \n",
    "    #document all columns that are missing with a negative 1\n",
    "    miss_cols = [\"airconditioningtypeid\",\"unitcnt\",\"poolcnt\",\"fireplacecnt\",\"garagecarcnt\",\"yardbuildingsqft17\",\"numberofstories\"]\n",
    "    for col in miss_cols:\n",
    "        chunk[col].fillna(-1,inplace=True)\n",
    "    chunk[\"bathroomcnt\"].fillna(chunk.calculatedbathnbr,inplace=True)\n",
    "    chunk[\"calculatedfinishedsquarefeet\"].fillna(chunk.finishedsquarefeet12,inplace=True)\n",
    "    if delete == 1:\n",
    "        del chunk[\"calculatedbathnbr\"]\n",
    "        del chunk[\"finishedsquarefeet12\"]\n",
    "    #Can we use tax value to come up with a hypothetical value of square feet?\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#dataset is too big so let's just assume that we are going to compress so that it is easier to work with\n",
    "#the data\n",
    "#function to check if an item is a percentage\n",
    "def is_percentage(item):\n",
    "    if str(item).endswith(\"%\") | str(item).endswith(\" MONTHS\"):\n",
    "        try:\n",
    "            float(item[:-1])\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#function to check if an item is a number\n",
    "def is_number(item):\n",
    "    try:\n",
    "        float(item)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "#Function to automate the data compression tasks\n",
    "def compress_chunk(chunk, has_id, dropcols=0):\n",
    "    #check to make sure that id is valid otherwise exceptions are thrown in the data and storage is not efficient (occurs at tail of data)\n",
    "    if has_id == 1:\n",
    "        id_is_valid = chunk.apply(lambda item: is_number(item[0]), axis=1)\n",
    "        chunk = chunk.loc[id_is_valid == True]\n",
    "        #print(\"Problem w/selection\")\n",
    "\n",
    "    #select string types\n",
    "    string_cols = chunk.select_dtypes(include=[\"object\"])\n",
    "    for s in string_cols.columns:\n",
    "        chunk[s]= chunk[s].fillna(\"\")\n",
    "        chunk[s] = chunk[s].str.rstrip()\n",
    "        #check if the column can be mostly considered a percentage or number (threshold 0.95)\n",
    "        col_is_percentage = chunk.apply(lambda item: is_percentage(item[s]), axis=1)\n",
    "        col_is_number = chunk.apply(lambda item: is_number(item[s]), axis=1)\n",
    "        #print(\"Column is number:\", col_is_number.sum())\n",
    "        #print(len(col_is_number))\n",
    "        #print(col_is_percentage.sum())\n",
    "        #print(len(col_is_percentage))\n",
    "        if col_is_percentage.sum()/len(col_is_percentage) > 0.95:\n",
    "            #print(\"Change to float: \", s)\n",
    "            chunk[s] = chunk[s].str.rstrip(\"%\")\n",
    "            chunk[s] = chunk[s].str.rstrip(\" MONTHS\")\n",
    "            chunk[s] = chunk[s].astype(float)\n",
    "        elif col_is_number.sum()/len(col_is_number) > 0.95:\n",
    "            print(s)\n",
    "            #drop rows that do not conform to the number requirements so errors are not thrown\n",
    "            chunk = chunk[col_is_number==True]\n",
    "            chunk[s] = chunk[s].astype(float,errors=\"ignore\")\n",
    "        else:\n",
    "            share_unique = len(string_cols[s].unique())/len(string_cols[s])\n",
    "            #Make sure that these columns are not subject issues due to case values (put everything into upper case)\n",
    "            chunk[s] = [st.upper() if st is not None else \"\" for st in chunk[s].astype(str)]\n",
    "            if share_unique < 0.50:\n",
    "                #if a small share is unique and the largest value count is the majority then drop this column from data\n",
    "                cnt_large_value = chunk[s].value_counts()[0]\n",
    "                if cnt_large_value/len(chunk[s]) >= 0.99 and dropcols == 1:\n",
    "                    chunk = chunk.drop(s, 1)\n",
    "                else:\n",
    "                    #just change to a category column otherwise\n",
    "                    #print(\"Change to category: \", s)\n",
    "                    chunk[s] = chunk[s].astype(\"category\")\n",
    "                    #print(\"error here\")\n",
    "    #want to check for float cols that are really integers\n",
    "    #that is floor(col) = round(col)\n",
    "    #dataset['deff'] = np.where(dataset['2016-11'] >= dataset['2016-12'], 0,1)\n",
    "    float_cols = chunk.select_dtypes(include=[\"float\"])\n",
    "    float_int_cols = []\n",
    "    for f in float_cols.columns:\n",
    "        #Also check if there is little variation in the float columns and drop these columns\n",
    "        if float_cols[f].std() < 0.0001 and dropcols == 1:\n",
    "            #print(\"Dropping\", f)\n",
    "            chunk = chunk.drop(f, 1)\n",
    "        else:\n",
    "            temp_floor = np.floor(chunk[f]*10)\n",
    "            temp_round = np.round(chunk[f]*10,0)\n",
    "            cnt_diff = np.where(temp_floor==temp_round,0,1).sum()\n",
    "            #if seems like everything is an integer\n",
    "            if cnt_diff == 0:\n",
    "                #print(\"Downcasting\", f)\n",
    "                float_int_cols.append(f)\n",
    "    for f in float_int_cols:\n",
    "        chunk[f]=pd.to_numeric(chunk[f],downcast=\"integer\")\n",
    "    #Drop columns that have too many missing values (greater than 50%)\n",
    "    missing = chunk.isnull().sum()\n",
    "    for key,val in missing.items():  #this data has too many exceptions\n",
    "        if missing[key]/len(chunk) > 0.50 and dropcols == 1:\n",
    "            chunk = chunk.drop(key, 1)\n",
    "    return chunk\n",
    "\n",
    "# Function to determine optimal chunk size based on memory constraint\n",
    "def optimal_chunk(file, maxmb, encodeval):\n",
    "    mem = 0\n",
    "    numrows = 0\n",
    "    while mem < maxmb:\n",
    "        numrows += 500\n",
    "        temp = pd.read_csv(file, nrows=numrows, encoding=encodeval)\n",
    "        mem = temp.memory_usage(deep=True).sum()/1048576\n",
    "    return numrows-500\n",
    "\n",
    "def compress_data(file,maxmb,dropcols,encodeval,parsedatecols,has_id=0):\n",
    "    memory_footprints_full = []\n",
    "    memory_footprints = []\n",
    "    \n",
    "    #obtain optimal chunk size\n",
    "    opt_chunk = optimal_chunk(file, maxmb, encodeval)\n",
    "    print(\"Optimal chunk for {}MB: {}\".format(maxmb, opt_chunk))\n",
    "    \n",
    "    # Get the memory usage needed prior to compression\n",
    "    chunk_iter = pd.read_csv(file, chunksize=opt_chunk, encoding=encodeval, parse_dates=parsedatecols)\n",
    "    numrows = 0\n",
    "    for chunk in chunk_iter:\n",
    "        numrows += opt_chunk\n",
    "        memory_footprints_full.append(chunk.memory_usage(deep=True).sum()/1048576)\n",
    "    total_memory_usage = sum(memory_footprints_full)\n",
    "    print(\"Memory usage (prior to compression): {}\".format(round(total_memory_usage,2)))\n",
    "    print(\"Number of rows in files: {}\".format(numrows))\n",
    "    \n",
    "    keep_cols = []\n",
    "    temp = pd.read_csv(file, nrows=2, parse_dates=parsedatecols)\n",
    "    print(\"Number of columns in original file: {}\".format(len(temp.columns)))\n",
    "    for c in temp.columns:\n",
    "        if c not in dropcols:\n",
    "            keep_cols.append(c)\n",
    "    print(\"Keep columns: \", keep_cols)\n",
    "\n",
    "    # Create synthetic data that will help us identify crucial columns to keep so we do not have to read into data frame\n",
    "    temp = pd.read_csv(file, nrows=opt_chunk, usecols=keep_cols, encoding=encodeval, parse_dates=parsedatecols)\n",
    "    temp = clean_zillow_chunk(temp,delete=0)\n",
    "    temp = compress_chunk(temp,has_id,dropcols=1)\n",
    "    print(\"Number of columns to keep: {}\".format(len(temp.columns)))\n",
    "    print(temp.columns)\n",
    "    newdata = []\n",
    "    alldata = []\n",
    "    # use the optimal chunk size and columns to keep to read in the chunks\n",
    "    chunk_iter = pd.read_csv(file, usecols=temp.columns, encoding=encodeval, chunksize=opt_chunk, parse_dates=parsedatecols)\n",
    "    num = 0\n",
    "    for chunk in chunk_iter:\n",
    "        num += 1\n",
    "        if int(num/20)==(num/20):\n",
    "            print(\"Processing Chunk\", num)\n",
    "        chunk = clean_zillow_chunk(chunk,delete=1)\n",
    "        chunk = compress_chunk(chunk,has_id,dropcols=0)\n",
    "        #we want some of the key data, but only certain columns\n",
    "        alldatacols = [\"parcelid\",\"regionidzip\",\"regionidcounty\",\"yearbuilt\",\"latitude\",\"longitude\",'propertylandusetypeid',\"bathroomcnt\",\"bedroomcnt\",\"taxvaluedollarcnt\",\"taxamount\",\"assessmentyear\"]\n",
    "        alldata.append(chunk[alldatacols])\n",
    "        #only keep ones that are in the train dataset (particular to the Zillow assignment)\n",
    "        chunk = pd.merge(chunk, train, how='inner', on='parcelid')\n",
    "        memory_footprints.append(chunk.memory_usage(deep=True).sum()/1048576)\n",
    "        #merge data into new set\n",
    "        newdata.append(chunk)\n",
    "        #try:\n",
    "        #    newdata=pd.concat([newdata, chunk], axis=0)\n",
    "        #except NameError:\n",
    "        #    newdata=chunk\n",
    "    total_memory_usage = sum(memory_footprints)\n",
    "    print(\"Memory usage (after compression): {}\".format(round(total_memory_usage,2)))\n",
    "    #print(\"Memory usage (newdata): {}\".format(round(newdata.memory_usage(deep=True).sum()/1048576,2)))\n",
    "    return [newdata,alldata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['propertycountylandusecode', 'propertyzoningdesc', 'structuretaxvaluedollarcnt', 'landtaxvaluedollarcnt', 'taxdelinquencyyear', 'taxdelinquencyflag', 'fips', 'rawcensustractandblock', 'censustractandblock']\n"
     ]
    }
   ],
   "source": [
    "#these columns are highly correlated with parcelid and therfore are redundant\n",
    "mcols99 = [\"fips\",\"rawcensustractandblock\",\"censustractandblock\"]\n",
    "drop_cols = [\"propertycountylandusecode\",\"propertyzoningdesc\", \"structuretaxvaluedollarcnt\",\"landtaxvaluedollarcnt\",\"taxdelinquencyyear\",\"taxdelinquencyflag\"]\n",
    "drop_cols.extend(mcols99)\n",
    "print(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal chunk for 3MB: 5000\n",
      "Memory usage (prior to compression): 1770.83\n",
      "Number of rows in files: 2990000\n",
      "Number of columns in original file: 58\n",
      "Keep columns:  ['parcelid', 'airconditioningtypeid', 'architecturalstyletypeid', 'basementsqft', 'bathroomcnt', 'bedroomcnt', 'buildingclasstypeid', 'buildingqualitytypeid', 'calculatedbathnbr', 'decktypeid', 'finishedfloor1squarefeet', 'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'finishedsquarefeet13', 'finishedsquarefeet15', 'finishedsquarefeet50', 'finishedsquarefeet6', 'fireplacecnt', 'fullbathcnt', 'garagecarcnt', 'garagetotalsqft', 'hashottuborspa', 'heatingorsystemtypeid', 'latitude', 'longitude', 'lotsizesquarefeet', 'poolcnt', 'poolsizesum', 'pooltypeid10', 'pooltypeid2', 'pooltypeid7', 'propertylandusetypeid', 'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip', 'roomcnt', 'storytypeid', 'threequarterbathnbr', 'typeconstructiontypeid', 'unitcnt', 'yardbuildingsqft17', 'yardbuildingsqft26', 'yearbuilt', 'numberofstories', 'fireplaceflag', 'taxvaluedollarcnt', 'assessmentyear', 'taxamount']\n",
      "Number of columns to keep: 29\n",
      "Index(['parcelid', 'airconditioningtypeid', 'bathroomcnt', 'bedroomcnt',\n",
      "       'buildingqualitytypeid', 'calculatedbathnbr',\n",
      "       'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'fireplacecnt',\n",
      "       'fullbathcnt', 'garagecarcnt', 'heatingorsystemtypeid', 'latitude',\n",
      "       'longitude', 'lotsizesquarefeet', 'poolcnt', 'propertylandusetypeid',\n",
      "       'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip',\n",
      "       'roomcnt', 'unitcnt', 'yardbuildingsqft17', 'yearbuilt',\n",
      "       'numberofstories', 'taxvaluedollarcnt', 'assessmentyear', 'taxamount'],\n",
      "      dtype='object')\n",
      "Processing Chunk 20\n",
      "Processing Chunk 40\n",
      "Processing Chunk 60\n",
      "Processing Chunk 80\n",
      "Processing Chunk 100\n",
      "Processing Chunk 120\n",
      "Processing Chunk 140\n",
      "Processing Chunk 160\n",
      "Processing Chunk 180\n",
      "Processing Chunk 200\n",
      "Processing Chunk 220\n",
      "Processing Chunk 240\n",
      "Processing Chunk 260\n",
      "Processing Chunk 280\n",
      "Processing Chunk 300\n",
      "Processing Chunk 320\n",
      "Processing Chunk 340\n",
      "Processing Chunk 360\n",
      "Processing Chunk 380\n",
      "Processing Chunk 400\n",
      "Processing Chunk 420\n",
      "Processing Chunk 440\n",
      "Processing Chunk 460\n",
      "Processing Chunk 480\n",
      "Processing Chunk 500\n",
      "Processing Chunk 520\n",
      "Processing Chunk 540\n",
      "Processing Chunk 560\n",
      "Processing Chunk 580\n",
      "Memory usage (after compression): 15.17\n"
     ]
    }
   ],
   "source": [
    "traindata, alldata = compress_data(\"properties_2016.csv\", 3, dropcols = drop_cols, encodeval=\"ISO-8859-1\", parsedatecols=None, has_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90811\n",
      "2985217\n"
     ]
    }
   ],
   "source": [
    "#merge data with train so we know which ones are actually sold\n",
    "#train data has all of the transactions prior to October 15, 2016 and only some after\n",
    "#since worried about selection let's just drop those prior to October 15, 2016?\n",
    "#note we do not need to keep information for households where they are not in the train set\n",
    "#note memory usage after compression is still 44.34 MB (quite huge)\n",
    "#Note also need to figure out how to replace some of the \"NaN\" values\n",
    "\n",
    "#check to make sure we have just the data that is in the train dataset\n",
    "numrows = 0\n",
    "for data in traindata:\n",
    "    numrows += len(data)\n",
    "print(numrows)\n",
    "\n",
    "numrows = 0\n",
    "for data in alldata:\n",
    "    numrows += len(data)\n",
    "print(numrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90811, 29)\n",
      "(2985217, 12)\n",
      "Missing Data\n",
      "parcelid                            0\n",
      "airconditioningtypeid               0\n",
      "bathroomcnt                       536\n",
      "bedroomcnt                        536\n",
      "buildingqualitytypeid           33447\n",
      "calculatedfinishedsquarefeet     1197\n",
      "fireplacecnt                        0\n",
      "fullbathcnt                      1718\n",
      "garagecarcnt                        0\n",
      "heatingorsystemtypeid           34731\n",
      "latitude                          536\n",
      "longitude                         536\n",
      "lotsizesquarefeet               10686\n",
      "poolcnt                             0\n",
      "propertylandusetypeid             536\n",
      "regionidcity                     2339\n",
      "regionidcounty                    536\n",
      "regionidneighborhood            54799\n",
      "regionidzip                       571\n",
      "roomcnt                           536\n",
      "unitcnt                             0\n",
      "yardbuildingsqft17                  0\n",
      "yearbuilt                        1292\n",
      "numberofstories                     0\n",
      "taxvaluedollarcnt                 537\n",
      "assessmentyear                    536\n",
      "taxamount                         542\n",
      "logerror                            0\n",
      "transactiondate                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#let's consider markets of los-angeles, Orange, and Ventura as distinct markets (to be evaluated separately)?\n",
    "#lets try to append all of the data together possible since only 11.99mb so create two sets of data\n",
    "finaltraindata = traindata[0]\n",
    "for data in traindata[1:len(traindata)]:\n",
    "    finaltraindata = pd.concat([finaltraindata,data],axis=0)\n",
    "print(finaltraindata.shape)\n",
    "\n",
    "finalalldata = alldata[0]\n",
    "for data in alldata[1:len(alldata)]:\n",
    "    finalalldata = pd.concat([finalalldata,data],axis=0)\n",
    "print(finalalldata.shape)\n",
    "\n",
    "print(\"Missing Data:  Train Data\")\n",
    "print(finaltraindata.isnull().sum())\n",
    "\n",
    "print(\"Missing Data:  All Data\")\n",
    "print(finalalldata.isnull().sum())\n",
    "\n",
    "#should we drop the data where latitude and longitude are missing?\n",
    "#how should we treat this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read-out the data so we can start from here in the future and not lose valuable time trying to process the data again\n",
    "#fulldata.to_csv(path_or_buf=None, sep=', ', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=False, date_format=None, doublequote=True, escapechar=None, decimal='.')[source]\n",
    "finaltraindata.to_csv(\"processed_train_2016.csv\", sep=',', encoding=\"ISO-8859-1\")\n",
    "finalalldata.to_csv(\"processed_all_2016.csv\", sep=',', encoding=\"ISO-8859-1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
